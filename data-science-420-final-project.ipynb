{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## DS420 Final Project\n## NIH Chest X-RAY Image Disease Classification","metadata":{}},{"cell_type":"markdown","source":"#### Team members: Yordanos Alemu, Kelsey Dinndorf, Jorania Ferreria Alves, & Rabab Mohamed Nafe","metadata":{}},{"cell_type":"markdown","source":"Data: https://www.kaggle.com/nickuzmenkov/nih-chest-xrays-tfrecords?select=preprocessed_data.csv\n\nThe dataset includes chest x-ray images to classify different diagnoses of diseases. There are 15 categories of diagnosis and 256 images (600 x 600). Additional patient information like age, sex, etc. are not included.\n\nDisease Categories: None, Atelectasis, Consolidation, Infiltration, Pneumothorax, Edema, Emphysema, Fibrosis, Effusion, Pneumonia, Pleural Thickening, Cardiomegaly, Nodule, Mass, Hernia","metadata":{}},{"cell_type":"code","source":"#import libraries\n\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploratory Data Analysis and Visualization","metadata":{}},{"cell_type":"code","source":"# Read the disease csv file (contains True/False)\ndf= pd.read_csv('/kaggle/input/nih-chest-xrays-tfrecords/preprocessed_data.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define disease categories as data\ndata= df.iloc[:,1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show data shape\ndf.shape\n\n#There are 16 columns and 112,120 rows","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show data info\ndf.info()\n\n#There are no missing values\n#all of the attributes are type boolean","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Countplot of No finding category\nsns.countplot(x='No Finding', data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define data columns, number of columns, and character columns\ncols = data.columns\nnum_cols = data._get_numeric_data().columns\nchar_cols=list(set(cols) - set(num_cols))\nchar_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1-hot encoding\nfrom sklearn.preprocessing import LabelEncoder\nle= LabelEncoder()\ndef encode(df):\n    for i in cols:\n        df[i]= le.fit_transform(df[i])\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#1-hot encode the disease categories\nencode(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concat the original image urls with the 1-hot encoded data\ndf=pd.concat([df.iloc[:,0],data], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Histogram of disease types\ndata.hist(bins=20, figsize=(15,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import libraries\nimport IPython.display as display\nimport random\nfrom functools import partial\nimport sys\nfrom numpy import load\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nimport time as timer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix\nsns.set(rc={'figure.figsize':(20,10)})\ncorrelation_matrix = data.corr().round(2)\nsns.heatmap(data=correlation_matrix, annot=True)\n\n'''\nThere are large correlations between the No Finding category an most of the other categories.\nThere is a fairly large correlation (0.18) between Emphysema and Pneumothorax.\nThere is a fairly large correlation (0.17) between Pneumonia and Edema.\nThere is a fairly large correlation (0.17) between Atelectasis and Effusion.\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pie chart of percent of x-ray images classified as a Mass disease\ndf.groupby('Mass').size().plot(kind='pie', autopct='%.2f')\n\n# 5.16% of the x-ray images are classified as Mass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define list of column headers\nheads = list(df.columns)[2:]\nheads","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split Image","metadata":{}},{"cell_type":"code","source":"file_loc = '/kaggle/input/nih-chest-xrays-tfrecords/'\n\nimage_loc = file_loc + 'data/'\n\nimage = os.listdir(image_loc)\n\nprint('The total images in TFRecord is ' + str(len(image)) + ' x-ray images')\n\n#There are 256 images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = [image_loc + x for x in image]\n\nfile_name = tf.io.gfile.glob(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Randomly sample the entire list to a 80-20% split, then set aside 10% of the train sets randomly as a validation set.","metadata":{}},{"cell_type":"code","source":"#Define training and test sets (index)\nALL = list(range(len(file_name)))\n\ntrain_valid = random.sample(ALL, int(len(ALL) * 0.8))\ntest_index = list(set(ALL) - set(train_valid))\n\ntrain_index = random.sample(train_valid, int(len(train_valid) * 0.9))\nvalid_index = list(set(train_valid) - set(train_index))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define training and test image file names\nTRAINING_FILENAMES, VALID_FILENAMES, TEST_FILENAMES = [file_name[index] for index in train_index], [file_name[index] for index in valid_index], [file_name[index] for index in test_index]\nTRAINING_FILENAMES","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\nprint(\"Validation TFRecord Files:\", len(VALID_FILENAMES))\nprint(\"Test TFRecord Files:\", len(TEST_FILENAMES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reducing Image Dimensionality","metadata":{}},{"cell_type":"code","source":"feature_description = {}\n\nfor elem in list(df.columns)[2:]:\n    feature_description[elem] = tf.io.FixedLenFeature([], tf.int64)\n    \nfeature_description['image'] = tf.io.FixedLenFeature([], tf.string)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we are reducing the image size to 50 X 50 ","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nIMAGE_ONE_AXIS = 50\nIMAGE_SIZE = [IMAGE_ONE_AXIS, IMAGE_ONE_AXIS]\nAUTOTUNE = tf.data.experimental.AUTOTUNE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Functions to read the data\ndef read_tfrecord(example):\n    example = tf.io.parse_single_example(example, feature_description)\n    image = tf.io.decode_jpeg(example[\"image\"], channels=3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n    \n    label = []\n    \n    for val in heads:\n        label.append(example[val])\n    \n    return image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(filenames):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_tfrecord)\n    \n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(filenames):\n    dataset = load_dataset(filenames)\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    \n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define train, valid, and test datasets\ntrain_dataset = get_dataset(TRAINING_FILENAMES)\nvalid_dataset = get_dataset(VALID_FILENAMES)\ntest_dataset = get_dataset(TEST_FILENAMES)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show the images for the training set to visualize\nimage_viz, label_viz = next(iter(train_dataset))\n\ndef show_batch(X, Y):\n    plt.figure(figsize=(20, 20))\n    for n in range(25):\n        ax = plt.subplot(5, 5, n + 1)\n        plt.imshow(X[n])\n        \n        result = [x for i, x in enumerate(heads) if Y[n][i]]\n        title = \"+\".join(result)\n        \n        if result == []: title = \"No Finding\"\n        \n        plt.title(title)\n        plt.axis(\"off\")\n\nshow_batch(image_viz.numpy(), label_viz.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_viz.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_viz.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA Model:","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nfrom IPython.display import display\ndisplay(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''# Read and print data:\nsess=tf.compat.v1.InteractiveSession()\n\n# Read TFRecord file\nreader = tf.compat.v1.TFRecordReader()\n#tf.compat.v1.python_io\nfilename_queue = tf.train.string_input_producer(['180-438.tfrec'])\n_, serialized_example = reader.read(filename_queue)\n\n# Define features\nread_features = {\n    'image/height': tf.FixedLenFeature([], dtype=tf.int64),\n    'image/width': tf.FixedLenFeature([], dtype=tf.int64),\n    'image/colorspace': tf.FixedLenFeature([], dtype=tf.string),\n    'image/class/label': tf.FixedLenFeature([], dtype=tf.int64),\n    'image/class/raw': tf.FixedLenFeature([], dtype=tf.int64),\n    'image/class/source': tf.FixedLenFeature([], dtype=tf.int64),\n    'image/class/text': tf.FixedLenFeature([], dtype=tf.string),\n    'image/format': tf.FixedLenFeature([], dtype=tf.string),\n    'image/filename': tf.FixedLenFeature([], dtype=tf.string),\n    'image/id': tf.FixedLenFeature([], dtype=tf.int64),\n    'image/encoded': tf.FixedLenFeature([], dtype=tf.string)\n}\n\n# Extract features from serialized data\nread_data = tf.parse_single_example(serialized=serialized_example,\n                                features=read_features)\n\n# Many tf.train functions use tf.train.QueueRunner,\n# so we need to start it before we read\ntf.train.start_queue_runners(sess)\n\n# Print features\nfor name, tensor in read_data.items():\n    print('{}: {}'.format(name, tensor.eval()))\n    '''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tree Classification Model (Machine Learning)","metadata":{}},{"cell_type":"code","source":"# Import libraries\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define y as response (No Finding category)\ny = data.iloc[:32, :1]\ny","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define y as numpy array\ny = y.values\ny","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define x as explanatory variables\nx = image_viz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check shape of x\nx.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check shape of y\ny.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert x tensor to an array\nproto_tensor = tf.make_tensor_proto(image_viz)  # convert `tensor a` to a proto tensor\nx = tf.make_ndarray(proto_tensor) \n\n# output has shape (2,3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reshape x from 4D to 2D\nreshaped = x.reshape(32, 7500)\nreshaped.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the explanatory data as newx\nnewx=reshaped","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check shape\nprint(newx.shape)\nprint(y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the train and test sets\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(newx,y, test_size = 0.2, random_state = 4)\nprint('Train set:', x_train.shape)\nprint('Test set:', x_test.shape)\nprint('Train set:', y_train.shape)\nprint('Test set:', y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree classifier\ntree_clf = DecisionTreeClassifier(max_depth=4, random_state=42)\ntree_clf.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accuracy evaluation\ny_predict=tree_clf.predict(x_test)\n\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, tree_clf.predict(x_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, y_predict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using a Decision Tree Classifier to classify the images as No Disease Finding or Yes Disease found gave a training set accuracy of 100%. The test set accuracy is about 42%, so this model is not great at predicting the disease based on the x-ray images.","metadata":{}},{"cell_type":"code","source":"#Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_predict)\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Model:","metadata":{}},{"cell_type":"code","source":"initial_learning_rate = 0.01\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=5, decay_rate=0.96, staircase=True\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_model(in_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), out_shape=len(heads)):\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(out_shape, activation='sigmoid'))\n\n    model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=lr_schedule),\n                  loss='binary_crossentropy',\n                  metrics=[tf.keras.metrics.AUC(name=\"auc\")])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = sum(1 for _ in tf.data.TFRecordDataset(TRAINING_FILENAMES))\nvalidation_size = sum(1 for _ in tf.data.TFRecordDataset(VALID_FILENAMES))\n\nepoch_steps = int(np.ceil(train_size/BATCH_SIZE))\nvalidation_steps = int(np.ceil(validation_size/BATCH_SIZE))\n\nepochs = 5\n\nprint(\"steps_per_epoch: \" + str(epoch_steps))\nprint(\"validation_steps: \" + str(validation_steps))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = define_model()\n\nhistory = model.fit(\n    train_dataset,\n    epochs=epochs,\n    validation_data=valid_dataset,\n    validation_steps = validation_steps\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, test_auc = model.evaluate(test_dataset, verbose=0)\n\nprint('Test auc:', test_auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The CNN model gives an accuracy of 70% when predicting x-ray images.","metadata":{}},{"cell_type":"markdown","source":"## Conclusions","metadata":{}},{"cell_type":"markdown","source":"Conclusion:\n\nThe model used for Machine Learning is the Tree Classifier \n\nThe final model for tree classifier we decided to use only what category which is “Finding”, the values in this column are stating whether or not there is a disease detected instead of including all 15 categories.\n\nThe accuracy from the tree classifier model gave us 100% from the training set accuracy, while for test set the accuracy was about 27%.This suggests that in the training set it appears to be some oversampling because it is not likely that the model can predict 100% accuracy\n\n\nThe model used for Deep Learning is the CNN model\n\nThe accuracy from the CNN model 74% to classify the disease images. This shows that the deep learning model (CNN) performed better than the decision tree.\n\nWhile working on the project there are some issues that we ran through like PCA\nWe tried to apply PCA but we encountered some problems when converting the image files from tfrec to jpeg.\n\nFurther Improvement:\n\nWe could try to implement PCA model and using all the categories to see how the model accuracy changes for both Tree Classifier and CNN\n\n\n\nReference: \nhttps://www.kaggle.com/hemanthhari/cv-hemanth\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}